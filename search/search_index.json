{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"model_constructor","text":"<p>Constructor to create pytorch model. </p>"},{"location":"#install","title":"Install","text":"<p><code>pip install model-constructor</code></p> <p>Or install from repo:</p> <p><code>pip install git+https://github.com/ayasyrev/model_constructor.git</code></p>"},{"location":"#how-to-use","title":"How to use","text":"<p>First import constructor class, then create model constructor object.</p> <p>Now you can change every part of model.</p> <pre><code>from model_constructor import ModelConstructor\n</code></pre> <pre><code>mc = ModelConstructor()\n</code></pre> <p>Check base parameters:</p> <pre><code>mc\n</code></pre> output <pre>ModelConstructor\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: ReLU, sa: False, se: False\n      stem sizes: [64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]</pre> <p>Check all parameters with <code>print_cfg</code> method:</p> <pre><code>mc.print_cfg()\n</code></pre> output <pre>ModelConstructor(\n      in_chans=3\n      num_classes=1000\n      block='BasicBlock'\n      conv_layer='ConvBnAct'\n      block_sizes=[64, 128, 256, 512]\n      layers=[2, 2, 2, 2]\n      norm='BatchNorm2d'\n      act_fn='ReLU'\n      expansion=1\n      groups=1\n      bn_1st=True\n      zero_bn=True\n      stem_sizes=[64]\n      stem_pool=\"MaxPool2d {'kernel_size': 3, 'stride': 2, 'padding': 1}\"\n      init_cnn='init_cnn'\n      make_stem='make_stem'\n      make_layer='make_layer'\n      make_body='make_body'\n      make_head='make_head')\n    </pre> <p>Now we have model constructor, default setting as resnet18. And we can get model after call it.</p> <pre><code>model = mc()\nmodel\n</code></pre> output <pre>ModelConstructor(\n      (stem): Sequential(\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      )\n      (body): Sequential(\n        (l_0): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n        (l_1): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): Sequential(\n              (id_conv): ConvBnAct(\n                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n        (l_2): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): Sequential(\n              (id_conv): ConvBnAct(\n                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n        (l_3): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): Sequential(\n              (id_conv): ConvBnAct(\n                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n      )\n      (head): Sequential(\n        (pool): AdaptiveAvgPool2d(output_size=1)\n        (flat): Flatten(start_dim=1, end_dim=-1)\n        (fc): Linear(in_features=512, out_features=1000, bias=True)\n      )\n    )</pre> <p>If you want to change model, just change constructor parameters. Lets create resnet50.</p> <pre><code>mc.expansion = 4\nmc.layers = [3,4,6,3]\n</code></pre> <p>We can check, what we changed (compare to default constructor).</p> <pre><code>mc.changed_fields\n</code></pre> output <pre>{'layers': [3, 4, 6, 3], 'expansion': 4}</pre> <pre><code>mc.print_changed_fields()\n</code></pre> output <pre>Changed fields:\n    layers: [3, 4, 6, 3]\n    expansion: 4\n    </pre> <p>We can compare changed with defaults.</p> <pre><code>mc.print_changed_fields(show_default=True)\n</code></pre> output <pre>Changed fields:\n    layers: [3, 4, 6, 3] | [2, 2, 2, 2]\n    expansion: 4 | 1\n    </pre> <p>Now we can look at model parts - stem, body, head.  </p> <pre><code>mc.body\n</code></pre> output <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_2): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_2): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_3): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_2): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_3): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_4): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_5): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n        (bl_2): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): ReLU(inplace=True)\n        )\n      )\n    )</pre>"},{"location":"#create-constructor-from-config","title":"Create constructor from config.","text":"<p>Alternative we can create config first and than create constructor from it. </p> <pre><code>from model_constructor import ModelCfg\n</code></pre> <pre><code>cfg = ModelCfg(\n    num_classes=10,\n    act_fn=nn.Mish,\n)\nprint(cfg)\n</code></pre> output <pre>ModelCfg(\n      in_chans=3\n      num_classes=10\n      block='BasicBlock'\n      conv_layer='ConvBnAct'\n      block_sizes=[64, 128, 256, 512]\n      layers=[2, 2, 2, 2]\n      norm='BatchNorm2d'\n      act_fn='Mish'\n      expansion=1\n      groups=1\n      bn_1st=True\n      zero_bn=True\n      stem_sizes=[64]\n      stem_pool=\"MaxPool2d {'kernel_size': 3, 'stride': 2, 'padding': 1}\")\n    </pre> <p>When creating config or constructor we can use string annotation for nn.Modules - it useful when creating model from config files.</p> <pre><code>cfg = ModelCfg(\n    num_classes=10,\n    act_fn=\"nn.SELU\",\n)\nprint(cfg.act_fn)\n</code></pre> output <pre>class 'torch.nn.modules.activation.SELU'</pre> <p>Now we can create constructor from config:</p> <pre><code>mc = ModelConstructor.from_cfg(cfg)\nmc\n</code></pre> output <pre>ModelConstructor\n      in_chans: 3, num_classes: 10\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: SELU, sa: , se: SEModule\n      stem sizes: [64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]"},{"location":"#more-modification","title":"More modification.","text":"<p>Main purpose of this module - fast and easy modify model.\nAnd here is the link to more modification to beat Imagenette leaderboard with add MaxBlurPool and modification to ResBlock notebook  </p>\n<p>But now lets create model as mxresnet50 from fastai forums tread  </p>\n<p>Lets create mxresnet constructor.</p>\n<pre><code>mc = ModelConstructor(name='MxResNet')\n</code></pre>\n<p>Then lets modify stem.</p>\n<pre><code>from model_constructor.xresnet import xresnet_stem\n</code></pre>\n<pre><code>mc.make_stem = xresnet_stem\nmc.stem_sizes = [3,32,64,64]\n</code></pre>\n<p>Now lets change activation function to Mish.\nHere is link to forum discussion  \nWe'v got Mish is in model_constructor.activations, but from pytorch 1.9 take it from torch:</p>\n<pre><code>from torch.nn import Mish\n</code></pre>\n<pre><code>mc.act_fn = Mish\n</code></pre>\n<pre><code>mc\n</code></pre>\n output  \n    <pre>MxResNet\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]</pre>\n\n\n<pre><code>mc.print_changed_fields()\n</code></pre>\n output  \n    <pre>Changed fields:\n    name: MxResNet\n    act_fn: Mish\n    stem_sizes: [3, 32, 64, 64]\n    make_stem: xresnet_stem\n    </pre>\n\n\n<p>Here is model:  </p>\n<pre><code>mc()\n</code></pre>\n output  \n    <pre>MxResNet(\n      act_fn: Mish, stem_sizes: [3, 32, 64, 64], make_stem: xresnet_stem\n      (stem): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_3): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      )\n      (body): Sequential(\n        (l_0): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n        )\n        (l_1): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): Sequential(\n              (id_conv): ConvBnAct(\n                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n        )\n        (l_2): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): Sequential(\n              (id_conv): ConvBnAct(\n                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n        )\n        (l_3): Sequential(\n          (bl_0): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): Sequential(\n              (id_conv): ConvBnAct(\n                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n          (bl_1): BasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): Mish(inplace=True)\n          )\n        )\n      )\n      (head): Sequential(\n        (pool): AdaptiveAvgPool2d(output_size=1)\n        (flat): Flatten(start_dim=1, end_dim=-1)\n        (fc): Linear(in_features=512, out_features=1000, bias=True)\n      )\n    )</pre>"},{"location":"#mxresnet50","title":"MXResNet50","text":"<p>Now lets make MxResNet50</p>\n<pre><code>mc.expansion = 4\nmc.layers = [3,4,6,3]\nmc.name = \"mxresnet50\"\n</code></pre>\n<pre><code>mc.print_changed_fields()\n</code></pre>\n output  \n    <pre>Changed fields:\n    name: mxresnet50\n    layers: [3, 4, 6, 3]\n    act_fn: Mish\n    expansion: 4\n    stem_sizes: [3, 32, 64, 64]\n    make_stem: xresnet_stem\n    </pre>\n\n\n<p>Now we have mxresnet50 constructor.\nWe can inspect every parts of it.\nAnd after call it we got model.</p>\n<pre><code>mc\n</code></pre>\n output  \n    <pre>mxresnet50\n      in_chans: 3, num_classes: 1000\n      expansion: 4, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [3, 4, 6, 3]</pre>\n\n\n<pre><code>mc.stem.conv_1\n</code></pre>\n output  \n    <pre>ConvBnAct(\n      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): Mish(inplace=True)\n    )</pre>\n\n\n<pre><code>mc.body.l_0.bl_0\n</code></pre>\n output  \n    <pre>BasicBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): Mish(inplace=True)\n    )</pre>\n\n\n<p>We can get model direct way:</p>\n<pre><code>mc = ModelConstructor(\n    name=\"MxResNet\",\n    act_fn=Mish,\n    layers=[3,4,6,3],\n    expansion=4,\n    make_stem=xresnet_stem,\n    stem_sizes=[32,64,64]\n)\nmodel = mc()\n</code></pre>\n<p>Another way:</p>\n<pre><code>model = ModelConstructor.create_model(\n    name=\"MxResNet\",\n    act_fn=Mish,\n    layers=[3,4,6,3],\n    expansion=4,\n    make_stem=xresnet_stem,\n    stem_sizes=[32,64,64]\n)\n</code></pre>"},{"location":"#yaresnet","title":"YaResNet","text":"<p>Now lets change Resblock to YaResBlock (Yet another ResNet, former NewResBlock) is in lib from version 0.1.0</p>\n<pre><code>from model_constructor.yaresnet import YaBasicBlock\n</code></pre>\n<pre><code>mc = ModelConstructor(name=\"YaResNet\")\nmc.block = YaBasicBlock\n</code></pre>\n<p>Or in one line:</p>\n<pre><code>mc = ModelConstructor(name=\"YaResNet\", block=YaBasicBlock)\n</code></pre>\n<p>That all. Now we have YaResNet constructor</p>\n<pre><code>mc.print_cfg()\n</code></pre>\n output  \n    <pre>ModelConstructor(\n      name='YaResNet'\n      in_chans=3\n      num_classes=1000\n      block='YaBasicBlock'\n      conv_layer='ConvBnAct'\n      block_sizes=[64, 128, 256, 512]\n      layers=[2, 2, 2, 2]\n      norm='BatchNorm2d'\n      act_fn='ReLU'\n      expansion=1\n      groups=1\n      bn_1st=True\n      zero_bn=True\n      stem_sizes=[64]\n      stem_pool=\"MaxPool2d {'kernel_size': 3, 'stride': 2, 'padding': 1}\"\n      init_cnn='init_cnn'\n      make_stem='make_stem'\n      make_layer='make_layer'\n      make_body='make_body'\n      make_head='make_head')\n    </pre>\n\n\n<p>Let see what we have.</p>\n<pre><code>mc.body.l_1.bl_0\n</code></pre>\n output  \n    <pre>YaBasicBlock(\n      (reduce): ConvBnAct(\n        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): ReLU(inplace=True)\n    )</pre>\n\n\n<p>Lets create <code>xResnet34</code> like model constructor:</p>\n<pre><code>from typing import Callable\n\nfrom model_constructor.helpers import ModSeq\n\n\nclass YaResnet34(ModelConstructor):\n    block: type[nn.Module] = YaBasicBlock\n    layers: list[int] = [3, 4, 6, 3]\n    make_stem: Callable[[ModelCfg], ModSeq] = xresnet_stem\n</code></pre>\n<pre><code>mc = YaResnet34()\nmc.print_cfg()\n</code></pre>\n output  \n    <pre>YaResnet34(\n      in_chans=3\n      num_classes=1000\n      block='YaBasicBlock'\n      conv_layer='ConvBnAct'\n      block_sizes=[64, 128, 256, 512]\n      layers=[3, 4, 6, 3]\n      norm='BatchNorm2d'\n      act_fn='ReLU'\n      expansion=1\n      groups=1\n      bn_1st=True\n      zero_bn=True\n      stem_sizes=[64]\n      stem_pool=\"MaxPool2d {'kernel_size': 3, 'stride': 2, 'padding': 1}\"\n      init_cnn='init_cnn'\n      make_stem='xresnet_stem'\n      make_layer='make_layer'\n      make_body='make_body'\n      make_head='make_head')\n    </pre>\n\n\n<p>And <code>xResnet50</code> like model can be inherited from <code>YaResnet34</code>:</p>\n<pre><code>class YaResnet50(YaResnet34):\n    expansion: int = 4\n</code></pre>\n<pre><code>mc = YaResnet50()\nmc\n</code></pre>\n output  \n    <pre>YaResnet50\n      in_chans: 3, num_classes: 1000\n      expansion: 4, groups: 1, dw: False, div_groups: None\n      act_fn: ReLU, sa: False, se: False\n      stem sizes: [64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [3, 4, 6, 3]</pre>"},{"location":"01_ModelConstructor/","title":"Model constructor.","text":"<p>Create and tune pytorch model.</p>"},{"location":"01_ModelConstructor/#modelconstructor-and-modelcfg","title":"ModelConstructor and ModelCfg","text":"<p>Main part of model_constructor - ModelConstructor and ModelCfg.</p> <pre><code>from model_constructor.model_constructor import ModelCfg, ModelConstructor\n</code></pre> <p>ModelCfg is base for model config, ModelConstructor got all we need to create model. And it subclassed from ModelCfg all config plus methods for create model.</p> <p>So we can create config and than constructor or model from it. Or create constructor or model from MOdelConstructor.</p> <p>Lets create base config.</p> <pre><code>cfg = ModelCfg()\ncfg.print_cfg()\n</code></pre> output <pre>ModelCfg(\n      in_chans=3\n      num_classes=1000\n      block='BasicBlock'\n      conv_layer='ConvBnAct'\n      block_sizes=[64, 128, 256, 512]\n      layers=[2, 2, 2, 2]\n      norm='BatchNorm2d'\n      act_fn='ReLU'\n      expansion=1\n      groups=1\n      bn_1st=True\n      zero_bn=True\n      stem_sizes=[64]\n      stem_pool=\"MaxPool2d {'kernel_size': 3, 'stride': 2, 'padding': 1}\")\n    </pre> <p>Now we can create model directly from config or throw creating constructor.</p> <pre><code>model = ModelConstructor.create_model(cfg)\n</code></pre> <pre><code>model_constructor = ModelConstructor.from_cfg(cfg)\nmodel = model_constructor()\n</code></pre>"},{"location":"01_ModelConstructor/#instantiate-config-or-constructor","title":"Instantiate config or constructor.","text":"<p>When initialize config or constructor, we can use string interpolations of nn.Modules instead of class. By default we search at torch.nn.</p> <pre><code>cfg = ModelCfg(act_fn=\"torch.nn.Mish\")\nprint(cfg.act_fn)\n</code></pre> output <pre>class 'torch.nn.modules.activation.Mish'</pre> <pre><code>cfg = ModelCfg(act_fn=\"nn.SELU\")\nprint(cfg.act_fn)\n</code></pre> output <pre>class 'torch.nn.modules.activation.SELU'</pre> <pre><code>cfg = ModelCfg(\n    act_fn=\"Mish\",\n    block=\"model_constructor.yaresnet.YaBasicBlock\",\n)\nprint(cfg.act_fn)\nprint(cfg.block)\n</code></pre> output <pre>class 'torch.nn.modules.activation.Mish'&gt;"},{"location":"01_ModelConstructor/#stem-body-head","title":"Stem, Body, Head.","text":"<p>By default constructor create <code>nn.Sequential</code> model with <code>stem</code>, <code>body</code> and <code>head</code>. We can check it at constructor stage.</p>\n<pre><code>model = ModelConstructor.create_model()\n</code></pre>\n<pre><code>for name, mod in model.named_children():\n    print(name)\n</code></pre>\n output  \n    <pre>stem\n    body\n    head\n    </pre>\n\n\n<p>Constructor create <code>stem</code>, <code>body</code> and <code>head</code> with <code>make_stem</code>, <code>make_body</code> and <code>make_head</code> methods. They are defined separately as functions with ModelCfg as argument.\nAnd we can change it on the fly as:\n<code>mc.make_stem = custom_stem</code>\n<code>mc.make_body = custom_body</code>\n<code>mc.make_head = custom_head</code>\nOr at initializations as:\n<code>mc = ModelConstructor(make_stem=custom_stem)</code></p>\n<pre><code>from model_constructor.model_constructor import make_stem, make_body, make_head, make_layer\n</code></pre>"},{"location":"01_ModelConstructor/#stem","title":"Stem","text":"<pre><code>stem = make_stem(cfg)\nstem\n</code></pre>\n output  \n    <pre>Sequential(\n      (conv_1): ConvBnAct(\n        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )</pre>"},{"location":"01_ModelConstructor/#layer","title":"Layer","text":"<p><code>make_layer</code> need <code>layer_num</code> argument - number of layer.\n<code>make_layer</code> separated with <code>make_body</code> - it can be one piece.</p>\n<pre><code>layer = make_layer(cfg, layer_num=0)\nlayer\n</code></pre>\n output  \n    <pre>Sequential(\n      (bl_0): YaBasicBlock(\n        (convs): Sequential(\n          (conv_0): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): Mish(inplace=True)\n          )\n          (conv_1): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (merge): Mish(inplace=True)\n      )\n      (bl_1): YaBasicBlock(\n        (convs): Sequential(\n          (conv_0): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): Mish(inplace=True)\n          )\n          (conv_1): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (merge): Mish(inplace=True)\n      )\n    )</pre>"},{"location":"01_ModelConstructor/#body","title":"Body","text":"<pre><code>body = make_body(cfg)\nbody\n</code></pre>\n output  \n    <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): Mish(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): Mish(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): YaBasicBlock(\n          (reduce): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): ConvBnAct(\n            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): Mish(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): Mish(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): YaBasicBlock(\n          (reduce): ConvBnAct(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): ConvBnAct(\n            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): Mish(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): Mish(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): YaBasicBlock(\n          (reduce): ConvBnAct(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): ConvBnAct(\n            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): Mish(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): Mish(inplace=True)\n        )\n      )\n    )</pre>"},{"location":"01_ModelConstructor/#head","title":"Head","text":"<pre><code>head = make_head(cfg)\nhead\n</code></pre>\n output  \n    <pre>Sequential(\n      (pool): AdaptiveAvgPool2d(output_size=1)\n      (flat): Flatten(start_dim=1, end_dim=-1)\n      (fc): Linear(in_features=512, out_features=1000, bias=True)\n    )</pre>"},{"location":"01_ModelConstructor/#model-constructor_1","title":"Model Constructor.","text":"<pre><code>mc  = ModelConstructor()\nmc\n</code></pre>\n output  \n    <pre>ModelConstructor\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: ReLU, sa: False, se: False\n      stem sizes: [64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]</pre>\n\n\n<pre><code>mc.stem\n</code></pre>\n output  \n    <pre>Sequential(\n      (conv_1): ConvBnAct(\n        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )</pre>\n\n\n<pre><code>mc.bn_1st = False\n</code></pre>\n<pre><code>mc.act_fn = nn.LeakyReLU\n</code></pre>\n<pre><code>mc.sa = SimpleSelfAttention\nmc.se = SEModule\n</code></pre>\n<pre><code>mc.body.l_0\n</code></pre>\n output  \n    <pre>Sequential(\n      (bl_0): BasicBlock(\n        (convs): Sequential(\n          (conv_0): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (conv_1): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (se): SEModule(\n            (squeeze): AdaptiveAvgPool2d(output_size=1)\n            (excitation): Sequential(\n              (reduce): Linear(in_features=64, out_features=4, bias=True)\n              (se_act): ReLU(inplace=True)\n              (expand): Linear(in_features=4, out_features=64, bias=True)\n              (se_gate): Sigmoid()\n            )\n          )\n        )\n        (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n      )\n      (bl_1): BasicBlock(\n        (convs): Sequential(\n          (conv_0): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (conv_1): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (se): SEModule(\n            (squeeze): AdaptiveAvgPool2d(output_size=1)\n            (excitation): Sequential(\n              (reduce): Linear(in_features=64, out_features=4, bias=True)\n              (se_act): ReLU(inplace=True)\n              (expand): Linear(in_features=4, out_features=64, bias=True)\n              (se_gate): Sigmoid()\n            )\n          )\n          (sa): SimpleSelfAttention(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n        (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n      )\n    )</pre>\n\n\n<p>model_constructor\nby ayasyrev</p>"},{"location":"02_1_Blocks/","title":"Blocks.","text":"<p>Base blocks for Resnet - Basic and Bottleneck Blocks.</p>"},{"location":"02_1_Blocks/#basicblock","title":"BasicBlock","text":"<pre><code>block = BasicBlock(64, 64)\nblock\n</code></pre> output <pre>BasicBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre>"},{"location":"02_1_Blocks/#bottleneckblock","title":"BottleneckBlock","text":"<pre><code>block = BottleneckBlock(64, 64, dw=True)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>block = BottleneckBlock(64, 64, groups=4)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>block = BottleneckBlock(64, 64, expansion=2, act_fn=nn.LeakyReLU, bn_1st=False)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre> <pre><code>lock = BottleneckBlock(32, 64, expansion=2, dw=True)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre> <pre><code>pool = partial(nn.AvgPool2d, kernel_size=2, ceil_mode=True)\n</code></pre> <pre><code>block = BottleneckBlock(32, 64, stride=2, dw=True, pool=pool)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (id_conv): Sequential(\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (id_conv): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>from model_constructor.layers import SEModule, SimpleSelfAttention\n</code></pre> <pre><code>block = BottleneckBlock(32, 64, stride=2, dw=True, pool=pool, se=SEModule)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (se): SEModule(\n          (squeeze): AdaptiveAvgPool2d(output_size=1)\n          (excitation): Sequential(\n            (reduce): Linear(in_features=64, out_features=4, bias=True)\n            (se_act): ReLU(inplace=True)\n            (expand): Linear(in_features=4, out_features=64, bias=True)\n            (se_gate): Sigmoid()\n          )\n        )\n      )\n      (id_conv): Sequential(\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (id_conv): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>block = BottleneckBlock(32, 64, stride=2, dw=True, pool=pool, se=SEModule, sa=SimpleSelfAttention)\nblock\n</code></pre> output <pre>BottleneckBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (se): SEModule(\n          (squeeze): AdaptiveAvgPool2d(output_size=1)\n          (excitation): Sequential(\n            (reduce): Linear(in_features=64, out_features=4, bias=True)\n            (se_act): ReLU(inplace=True)\n            (expand): Linear(in_features=4, out_features=64, bias=True)\n            (se_gate): Sigmoid()\n          )\n        )\n        (sa): SimpleSelfAttention(\n          (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n        )\n      )\n      (id_conv): Sequential(\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (id_conv): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <p>model_constructor by ayasyrev</p>"},{"location":"02_2_layers/","title":"Layers","text":"<p>Basic layers for constructor.</p>"},{"location":"02_2_layers/#convbnact-nnmodule","title":"ConvBnAct - nn.module","text":"<pre><code>conv_layer = ConvBnAct(32, 32)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 32, kernel_size=1)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 32, stride=2)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 32, groups=32)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 64, act_fn=False)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 64, bn_layer=False)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 64, pre_act=True)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (act_fn): ReLU(inplace=True)\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )</pre> <pre><code>conv_layer[0]\n</code></pre> output <pre>ReLU(inplace=True)</pre> <pre><code>conv_layer = ConvBnAct(32, 64, bn_1st=True, pre_act=True)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (act_fn): ReLU(inplace=True)\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 64, bn_1st=True)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvBnAct(32, 64, bn_1st=True, act_fn=nn.LeakyReLU)\nconv_layer\n</code></pre> output <pre>ConvBnAct(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre>"},{"location":"02_2_layers/#simpleselfattention","title":"SimpleSelfAttention","text":"<p>SA module from mxresnet at fastai.</p> <pre><code>sa = SimpleSelfAttention(32)\nsa\n</code></pre> output <pre>SimpleSelfAttention(\n      (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n    )</pre>"},{"location":"02_2_layers/#semodule","title":"SEModule","text":"<pre><code>se_block = SEModule(128)\nse_block\n</code></pre> output <pre>SEModule(\n      (squeeze): AdaptiveAvgPool2d(output_size=1)\n      (excitation): Sequential(\n        (reduce): Linear(in_features=128, out_features=8, bias=True)\n        (se_act): ReLU(inplace=True)\n        (expand): Linear(in_features=8, out_features=128, bias=True)\n        (se_gate): Sigmoid()\n      )\n    )</pre> <pre><code>se_block = SEModule(128, rd_channels=32)\nse_block\n</code></pre> output <pre>SEModule(\n      (squeeze): AdaptiveAvgPool2d(output_size=1)\n      (excitation): Sequential(\n        (reduce): Linear(in_features=128, out_features=32, bias=True)\n        (se_act): ReLU(inplace=True)\n        (expand): Linear(in_features=32, out_features=128, bias=True)\n        (se_gate): Sigmoid()\n      )\n    )</pre>"},{"location":"02_2_layers/#semoduleconv","title":"SEModuleConv","text":"<pre><code>se_block = SEModuleConv(128)\nse_block\n</code></pre> output <pre>SEModuleConv(\n      (squeeze): AdaptiveAvgPool2d(output_size=1)\n      (excitation): Sequential(\n        (reduce): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n        (se_act): ReLU(inplace=True)\n        (expand): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n        (gate): Sigmoid()\n      )\n    )</pre> <pre><code>se_block = SEModuleConv(128, reduction=32)\nse_block\n</code></pre> output <pre>SEModuleConv(\n      (squeeze): AdaptiveAvgPool2d(output_size=1)\n      (excitation): Sequential(\n        (reduce): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n        (se_act): ReLU(inplace=True)\n        (expand): Conv2d(4, 128, kernel_size=(1, 1), stride=(1, 1))\n        (gate): Sigmoid()\n      )\n    )</pre> <pre><code>se_block = SEModuleConv(128, rd_channels=32)\nse_block\n</code></pre> output <pre>SEModuleConv(\n      (squeeze): AdaptiveAvgPool2d(output_size=1)\n      (excitation): Sequential(\n        (reduce): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n        (se_act): ReLU(inplace=True)\n        (expand): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n        (gate): Sigmoid()\n      )\n    )</pre> <pre><code>se_block = SEModuleConv(128, reduction=4, rd_channels=16, rd_max=True)\nse_block\n</code></pre> output <pre>SEModuleConv(\n      (squeeze): AdaptiveAvgPool2d(output_size=1)\n      (excitation): Sequential(\n        (reduce): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n        (se_act): ReLU(inplace=True)\n        (expand): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n        (gate): Sigmoid()\n      )\n    )</pre> <p>model_constructor by ayasyrev</p>"},{"location":"02_XResNet/","title":"XResNet.","text":"<p>xResNet model.</p>"},{"location":"02_XResNet/#xresnet-constructor","title":"XResNet constructor.","text":"<pre><code>xresnet  = ModelConstructor(\n    name='XResNet',\n    make_stem=xresnet_stem,\n    stem_sizes=[3, 32, 64, 64],\n    act_fn=torch.nn.Mish,\n)\n</code></pre> <pre><code>xresnet\n</code></pre> output <pre>XResNet\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]</pre> <pre><code>xresnet.print_changed_fields()\n</code></pre> output <pre>Changed fields:\n    name: XResNet\n    act_fn: Mish\n    stem_sizes: [3, 32, 64, 64]\n    make_stem: xresnet_stem\n    </pre> <pre><code>xresnet.stem\n</code></pre> <pre><code>/home/aya/mambaforge/envs/mc/lib/python3.10/site-packages/torch/nn/modules/conv.py:137: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n  self.weight = Parameter(torch.empty(\n</code></pre> output <pre>Sequential(\n      (conv_0): ConvBnAct(\n        (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (conv_1): ConvBnAct(\n        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (conv_2): ConvBnAct(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (conv_3): ConvBnAct(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )</pre> <pre><code>xresnet.body\n</code></pre> output <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n    )</pre> <pre><code>xresnet.head\n</code></pre> output <pre>Sequential(\n      (pool): AdaptiveAvgPool2d(output_size=1)\n      (flat): Flatten(start_dim=1, end_dim=-1)\n      (fc): Linear(in_features=512, out_features=1000, bias=True)\n    )</pre>"},{"location":"02_XResNet/#xresnet-constructors","title":"xResNet constructors","text":"<p>Lets create constructor class for xResnet.</p> <pre><code>class XResNet(ModelConstructor):\n    make_stem: Callable[[ModelCfg], ModSeq] = xresnet_stem\n    stem_sizes: list[int] = [32, 32, 64]\n    pool: Optional[Callable[[Any], nn.Module]] = partial(\n        nn.AvgPool2d, kernel_size=2, ceil_mode=True\n    )\n</code></pre> <p>xResnet34 inherit from xResnet.</p> <pre><code>class XResNet34(XResNet):\n    layers: list[int] = [3, 4, 6, 3]\n</code></pre> <p>xResnet50 inherit from xResnet34.</p> <pre><code>class XResNet50(XResNet34):\n    block: type[nn.Module] = BottleneckBlock\n    block_sizes: list[int] = [256, 512, 1024, 2048]\n</code></pre> <p>Now we can create constructor from class adn change model parameters during initialization or after.</p> <pre><code>mc = XResNet34(num_classes=10)\nmc\n</code></pre> output <pre>XResNet34\n      in_chans: 3, num_classes: 10\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: ReLU, sa: False, se: False\n      stem sizes: [32, 32, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [3, 4, 6, 3]</pre> <pre><code>mc = XResNet50()\nmc\n</code></pre> output <pre>XResNet50\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: ReLU, sa: False, se: False\n      stem sizes: [32, 32, 64], stride on 0\n      body sizes [256, 512, 1024, 2048]\n      layers: [3, 4, 6, 3]</pre> <p>To create model - call model constructor object.</p> <pre><code>model = mc()\n</code></pre> <p>model_constructor by ayasyrev</p>"},{"location":"03_MXResNet/","title":"MXResNet.","text":"<p>MXResNet model.</p> <p>MXResNet model, forum discussion</p>"},{"location":"03_MXResNet/#mxresnet-constructor","title":"MXResNet constructor.","text":"<pre><code>mxresnet  = ModelConstructor(\n    name='MXResNet',\n    make_stem=xresnet_stem,\n    stem_sizes=[3, 32, 64, 64],\n    act_fn=torch.nn.Mish,\n)\n</code></pre> <pre><code>mxresnet\n</code></pre> output <pre>MXResNet\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]</pre> <pre><code>mxresnet.print_changed_fields()\n</code></pre> output <pre>Changed fields:\n    name: MXResNet\n    act_fn: Mish\n    stem_sizes: [3, 32, 64, 64]\n    make_stem: xresnet_stem\n    </pre> <pre><code>mxresnet.stem\n</code></pre> <pre><code>/home/aya/mambaforge/envs/mc/lib/python3.10/site-packages/torch/nn/modules/conv.py:137: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n  self.weight = Parameter(torch.empty(\n</code></pre> output <pre>Sequential(\n      (conv_0): ConvBnAct(\n        (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (conv_1): ConvBnAct(\n        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (conv_2): ConvBnAct(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (conv_3): ConvBnAct(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish(inplace=True)\n      )\n      (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )</pre> <pre><code>mxresnet.body\n</code></pre> output <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n    )</pre> <pre><code>mxresnet.body\n</code></pre> output <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): Sequential(\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n        (bl_1): BasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): Mish(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (act_fn): Mish(inplace=True)\n        )\n      )\n    )</pre> <pre><code>mxresnet.head\n</code></pre> output <pre>Sequential(\n      (pool): AdaptiveAvgPool2d(output_size=1)\n      (flat): Flatten(start_dim=1, end_dim=-1)\n      (fc): Linear(in_features=512, out_features=1000, bias=True)\n    )</pre>"},{"location":"03_MXResNet/#mxresnet-constructors","title":"MxResNet constructors","text":"<p>Lets create constructor class for MxResnet.</p> <p>Base MxResNet inherit from XResNet.</p> <pre><code>class MxResNet(XResNet):\n    stem_sizes: list[int] = [3, 32, 64, 64]\n    act_fn: type[nn.Module] = nn.Mish\n</code></pre> <p>MXResnet34 inherit from MXResnet.</p> <pre><code>class MxResNet34(MxResNet):\n    layers: list[int] = [3, 4, 6, 3]\n</code></pre> <p>MXResnet50 inherit from MXResnet34.</p> <pre><code>class MxResNet50(MxResNet34):\n    expansion: int = 4\n    block_sizes: list[int] = [256, 512, 1024, 2048]\n</code></pre> <p>Now we can create constructor from class adn change model parameters during initialization or after.</p> <pre><code>mc = MxResNet34(num_classes=10)\nmc\n</code></pre> output <pre>MxResNet34\n      in_chans: 3, num_classes: 10\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [3, 4, 6, 3]</pre> <pre><code>mc = MxResNet50()\nmc\n</code></pre> output <pre>MxResNet50\n      in_chans: 3, num_classes: 1000\n      expansion: 4, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [256, 512, 1024, 2048]\n      layers: [3, 4, 6, 3]</pre> <p>To create model - call model constructor object or create model from constructor.</p> <pre><code>model = mc()\n</code></pre> <pre><code>model = MxResNet34.create_model()\n</code></pre> <p>model_constructor by ayasyrev</p>"},{"location":"04_YaResNet/","title":"YaResNet.","text":"<p>Yet Another ResNet model.</p> <pre><code>from model_constructor.yaresnet import YaBasicBlock, YaBottleneckBlock\n</code></pre>"},{"location":"04_YaResNet/#yabasicblock-yabottleneckblock","title":"YaBasicBlock, YaBottleneckBlock","text":"<pre><code>bl = YaBasicBlock(64, 64)\nbl\n</code></pre> output <pre>YaBasicBlock(\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (merge): ReLU(inplace=True)\n    )</pre> <pre><code>pool = partial(nn.AvgPool2d, kernel_size=2, ceil_mode=True)\n</code></pre> <pre><code>bl = YaBottleneckBlock(64, 128, stride=2, pool=pool, act_fn=nn.LeakyReLU, bn_1st=False)\nbl\n</code></pre> output <pre>YaBottleneckBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre> <pre><code>bl = YaBottleneckBlock(\n    64,\n    128,\n    expansion=2,\n    stride=2,\n    pool=pool,\n    act_fn=nn.LeakyReLU,\n    bn_1st=False,\n    groups=4,\n)\nbl\n</code></pre> output <pre>YaBottleneckBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre> <pre><code>bl = YaBottleneckBlock(\n    64,\n    128,\n    stride=2,\n    pool=pool,\n    act_fn=nn.LeakyReLU,\n    bn_1st=False,\n    div_groups=4,\n)\nbl\n</code></pre> output <pre>YaBottleneckBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre> <pre><code>bl = YaBasicBlock(\n    64,\n    128,\n    stride=2,\n    pool=pool,\n    act_fn=nn.Mish,\n    bn_1st=False,\n    dw=True,\n)\nbl\n</code></pre> output <pre>YaBasicBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n          (act_fn): Mish(inplace=True)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): Mish(inplace=True)\n    )</pre>"},{"location":"04_YaResNet/#se-sa","title":"Se, Sa","text":"<pre><code>from model_constructor.layers import SimpleSelfAttention, SEModule\n</code></pre> <pre><code>bl = YaBottleneckBlock(\n    64,\n    128,\n    stride=2,\n    pool=pool,\n    act_fn=nn.GELU,\n    dw=True,\n    se=SEModule,\n)\nbl\n</code></pre> output <pre>YaBottleneckBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): GELU(approximate='none')\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): GELU(approximate='none')\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (se): SEModule(\n          (squeeze): AdaptiveAvgPool2d(output_size=1)\n          (excitation): Sequential(\n            (reduce): Linear(in_features=128, out_features=8, bias=True)\n            (se_act): ReLU(inplace=True)\n            (expand): Linear(in_features=8, out_features=128, bias=True)\n            (se_gate): Sigmoid()\n          )\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): GELU(approximate='none')\n    )</pre> <pre><code>bl = YaBottleneckBlock(\n    64,\n    128,\n    stride=2,\n    pool=pool,\n    act_fn=nn.LeakyReLU,\n    dw=True,\n    sa=SimpleSelfAttention,\n)\nbl\n</code></pre> output <pre>YaBottleneckBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (sa): SimpleSelfAttention(\n          (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre> <pre><code>bl = YaBottleneckBlock(\n    64,\n    128,\n    expansion=4,\n    stride=2,\n    pool=pool,\n    act_fn=nn.LeakyReLU,\n    dw=True,\n    se=SEModule,\n    sa=SimpleSelfAttention)\nbl\n</code></pre> output <pre>YaBottleneckBlock(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (se): SEModule(\n          (squeeze): AdaptiveAvgPool2d(output_size=1)\n          (excitation): Sequential(\n            (reduce): Linear(in_features=128, out_features=8, bias=True)\n            (se_act): ReLU(inplace=True)\n            (expand): Linear(in_features=8, out_features=128, bias=True)\n            (se_gate): Sigmoid()\n          )\n        )\n        (sa): SimpleSelfAttention(\n          (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n        )\n      )\n      (id_conv): ConvBnAct(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): LeakyReLU(negative_slope=0.01, inplace=True)\n    )</pre>"},{"location":"04_YaResNet/#yaresnet-constructor","title":"YaResNet constructor.","text":"<pre><code>from model_constructor import ModelConstructor\nfrom model_constructor.xresnet import xresnet_stem\n\n\nyaresnet  = ModelConstructor(\n    block=YaBasicBlock,\n    make_stem=xresnet_stem,\n    stem_sizes=[3, 32, 64, 64],\n    name='YaResNet',\n)\n</code></pre> <pre><code>yaresnet\n</code></pre> output <pre>YaResNet\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: ReLU, sa: False, se: False\n      stem sizes: [3, 32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [2, 2, 2, 2]</pre> <pre><code>yaresnet.print_changed_fields()\n</code></pre> output <pre>Changed fields:\n    name: YaResNet\n    block: YaBasicBlock\n    stem_sizes: [3, 32, 64, 64]\n    make_stem: xresnet_stem\n    </pre> <pre><code>yaresnet.stem\n</code></pre> output <pre>Sequential(\n      (conv_0): ConvBnAct(\n        (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (conv_1): ConvBnAct(\n        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (conv_2): ConvBnAct(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (conv_3): ConvBnAct(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )</pre> <pre><code>yaresnet.body\n</code></pre> output <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): YaBasicBlock(\n          (reduce): ConvBnAct(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): ConvBnAct(\n            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): YaBasicBlock(\n          (reduce): ConvBnAct(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): ConvBnAct(\n            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): YaBasicBlock(\n          (reduce): ConvBnAct(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (id_conv): ConvBnAct(\n            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): YaBasicBlock(\n          (convs): Sequential(\n            (conv_0): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1): ConvBnAct(\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n    )</pre> <pre><code>yaresnet.head\n</code></pre> output <pre>Sequential(\n      (pool): AdaptiveAvgPool2d(output_size=1)\n      (flat): Flatten(start_dim=1, end_dim=-1)\n      (fc): Linear(in_features=512, out_features=1000, bias=True)\n    )</pre> <p>Lots of experiments showed that it worth trying Mish activation function.</p> <pre><code>yaresnet.act_fn = torch.nn.Mish\nyaresnet()\n</code></pre> output <pre>YaResNet(\n      block: YaBasicBlock, act_fn: Mish, stem_sizes: [3, 32, 64, 64], make_stem: xresnet_stem\n      (stem): Sequential(\n        (conv_0): ConvBnAct(\n          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_1): ConvBnAct(\n          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_2): ConvBnAct(\n          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (conv_3): ConvBnAct(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish(inplace=True)\n        )\n        (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      )\n      (body): Sequential(\n        (l_0): Sequential(\n          (bl_0): YaBasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (merge): Mish(inplace=True)\n          )\n          (bl_1): YaBasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (merge): Mish(inplace=True)\n          )\n        )\n        (l_1): Sequential(\n          (bl_0): YaBasicBlock(\n            (reduce): ConvBnAct(\n              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (merge): Mish(inplace=True)\n          )\n          (bl_1): YaBasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (merge): Mish(inplace=True)\n          )\n        )\n        (l_2): Sequential(\n          (bl_0): YaBasicBlock(\n            (reduce): ConvBnAct(\n              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (merge): Mish(inplace=True)\n          )\n          (bl_1): YaBasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (merge): Mish(inplace=True)\n          )\n        )\n        (l_3): Sequential(\n          (bl_0): YaBasicBlock(\n            (reduce): ConvBnAct(\n              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (id_conv): ConvBnAct(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (merge): Mish(inplace=True)\n          )\n          (bl_1): YaBasicBlock(\n            (convs): Sequential(\n              (conv_0): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): Mish(inplace=True)\n              )\n              (conv_1): ConvBnAct(\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (merge): Mish(inplace=True)\n          )\n        )\n      )\n      (head): Sequential(\n        (pool): AdaptiveAvgPool2d(output_size=1)\n        (flat): Flatten(start_dim=1, end_dim=-1)\n        (fc): Linear(in_features=512, out_features=1000, bias=True)\n      )\n    )</pre> <pre><code>yaresnet.se = SEModule\n</code></pre> <pre><code>yaresnet.body.l_0.bl_0\n</code></pre>"},{"location":"04_YaResNet/#yaresnet34-yaresnet50","title":"YaResnet34, YaResnet50","text":"<p>We has <code>Resnet34</code> and <code>Resnet50</code> like models predefined, we can impoer it as: <code>from model_constructor.yaresnet import YaResNet34, YaResNet50</code> But lets create it.</p> <pre><code>class YaResNet(ModelConstructor):\n    make_stem: Callable[[ModelCfg], ModSeq] = xresnet_stem\n    stem_sizes: list[int] = [32, 64, 64]\n    block: type[nn.Module] = YaBasicBlock\n    act_fn: type[nn.Module] = nn.Mish\n    pool: Optional[Callable[[Any], nn.Module]] = partial(\n        nn.AvgPool2d, kernel_size=2, ceil_mode=True\n)\n</code></pre> <pre><code>class YaResNet34(YaResNet):\n    layers: list[int] = [3, 4, 6, 3]\n</code></pre> <pre><code>yaresnet34 = YaResNet34()\nyaresnet34\n</code></pre> output <pre>YaResNet34\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [32, 64, 64], stride on 0\n      body sizes [64, 128, 256, 512]\n      layers: [3, 4, 6, 3]</pre> <pre><code>class YaResNet50(YaResNet34):\n    block: type[nn.Module] = YaBottleneckBlock\n    block_sizes: list[int] = [256, 512, 1024, 2048]\n</code></pre> <pre><code>yaresnet50 = YaResNet50()\nyaresnet50\n</code></pre> output <pre>YaResNet50\n      in_chans: 3, num_classes: 1000\n      expansion: 1, groups: 1, dw: False, div_groups: None\n      act_fn: Mish, sa: False, se: False\n      stem sizes: [32, 64, 64], stride on 0\n      body sizes [256, 512, 1024, 2048]\n      layers: [3, 4, 6, 3]</pre> <p>model_constructor by ayasyrev</p>"},{"location":"05_Twist/","title":"Twist.","text":"<p>Create and tune models with Twist layers.</p>"},{"location":"05_Twist/#convtwist","title":"ConvTwist","text":"<pre><code>from model_constructor.twist import ConvTwist\n</code></pre> <pre><code>ConvTwist(64,64)\n</code></pre> output <pre>ConvTwist(\n      twist: False, permute: True, same: True, groups: 8\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n    )</pre> <pre><code>ConvTwist.twist, ConvTwist.permute\n</code></pre> output <pre>(False, True)</pre> <pre><code>ConvTwist.use_groups, ConvTwist.groups_ch\n</code></pre> output <pre>(True, 8)</pre> <pre><code>ConvTwist(64, 64)\n</code></pre> output <pre>ConvTwist(\n      twist: False, permute: True, same: True, groups: 8\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n    )</pre> <pre><code>ConvTwist.twist = True\nConvTwist.permute = False\nConvTwist(64, 64)\n</code></pre> output <pre>ConvTwist(\n      twist: True, permute: False, same: True, groups: 8\n      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n    )</pre>"},{"location":"05_Twist/#convlayertwist","title":"ConvLayerTwist","text":"<pre><code>class ConvLayerTwist(ConvLayer):  # replace Conv2d by Twist\n    Conv2d = ConvTwist\n</code></pre> <pre><code>ConvLayerTwist(64, 64, stride=1)\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: True, permute: False, same: True, groups: 8\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>ConvLayer.Conv2d\n</code></pre> output <pre>torch.nn.modules.conv.Conv2d</pre> <pre><code>ConvLayerTwist.Conv2d\n</code></pre> output <pre>model_constructor.twist.ConvTwist</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: True, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>ConvTwist.twist = False\nconv_layer = ConvLayerTwist(32, 64)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, act=False)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, bn_layer=False)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, bn_1st=True)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, bn_1st=True, act_fn=nn.LeakyReLU())\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): LeakyReLU(negative_slope=0.01)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, ks=1)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, ks=1, stride=2)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>conv_layer = ConvLayerTwist(32, 64, stride=2)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 4\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>ConvTwist.groups_ch = 4\nconv_layer = ConvLayerTwist(32, 64, stride=2)\nconv_layer\n</code></pre> output <pre>ConvLayerTwist(\n      (conv): ConvTwist(\n        twist: False, permute: False, same: False, groups: 8\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): ReLU(inplace=True)\n    )</pre>"},{"location":"05_Twist/#newresblocktwist","title":"NewResBlockTwist","text":"<pre><code>from model_constructor.twist import NewResBlockTwist\n</code></pre> <pre><code>bl = NewResBlockTwist(4, 64, 64, sa=True)\nbl\n</code></pre> output <pre>NewResBlockTwist(\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: True, groups: 16\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n          )\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (sa): SimpleSelfAttention(\n          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n        )\n      )\n      (merge): ReLU(inplace=True)\n    )</pre> <pre><code>bl = NewResBlockTwist(4, 64, 64, stride=2)\nbl\n</code></pre> output <pre>NewResBlockTwist(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: True, groups: 16\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n          )\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (merge): ReLU(inplace=True)\n    )</pre> <pre><code>bl = NewResBlockTwist(4, 64, 128, stride=2)\nbl\n</code></pre> output <pre>NewResBlockTwist(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: True, groups: 32\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          )\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (idconv): ConvLayer(\n        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): ReLU(inplace=True)\n    )</pre> <pre><code>bl = NewResBlockTwist(\n    4,\n    64,\n    128,\n    stride=2,\n    act_fn=nn.LeakyReLU(),\n    bn_1st=False,\n)\nbl\n</code></pre> output <pre>NewResBlockTwist(\n      (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (act_fn): LeakyReLU(negative_slope=0.01)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: True, groups: 32\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          )\n          (act_fn): LeakyReLU(negative_slope=0.01)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (idconv): ConvLayer(\n        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (merge): LeakyReLU(negative_slope=0.01)\n    )</pre>"},{"location":"05_Twist/#resblocktwist","title":"ResBlockTwist","text":"<pre><code>from model_constructor.twist import ResBlockTwist\n</code></pre> <pre><code>bl = ResBlockTwist(4, 64, 64, sa=True)\nbl\n</code></pre> output <pre>ResBlockTwist(\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: True, groups: 16\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n          )\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (sa): SimpleSelfAttention(\n          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n        )\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>bl = ResBlockTwist(4, 64, 64, stride=2)\nbl\n</code></pre> output <pre>ResBlockTwist(\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: False, groups: 16\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n          )\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (act_fn): ReLU(inplace=True)\n    )</pre> <pre><code>bl = ResBlockTwist(4, 64, 128, stride=2)\nbl\n</code></pre> output <pre>ResBlockTwist(\n      (convs): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1_twist): ConvLayerTwist(\n          (conv): ConvTwist(\n            twist: False, permute: False, same: False, groups: 32\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n          )\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (idconv): ConvLayer(\n        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (act_fn): ReLU(inplace=True)\n    )</pre>"},{"location":"05_Twist/#model","title":"Model","text":"<pre><code>model  = Net(expansion=4, layers=[3, 4, 6, 3])\n</code></pre> <pre><code>model.block = NewResBlockTwist\n</code></pre> <pre><code>model.body\n</code></pre> output <pre>Sequential(\n      (l_0): Sequential(\n        (bl_0): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 16\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n              )\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (idconv): ConvLayer(\n            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 16\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n              )\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_2): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 16\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n              )\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n      (l_1): Sequential(\n        (bl_0): NewResBlockTwist(\n          (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 32\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              )\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (idconv): ConvLayer(\n            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 32\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              )\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_2): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 32\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              )\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_3): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 32\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              )\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n      (l_2): Sequential(\n        (bl_0): NewResBlockTwist(\n          (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 64\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              )\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (idconv): ConvLayer(\n            (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 64\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              )\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_2): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 64\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              )\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_3): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 64\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              )\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_4): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 64\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              )\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_5): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 64\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              )\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n      (l_3): Sequential(\n        (bl_0): NewResBlockTwist(\n          (reduce): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 128\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n              )\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (idconv): ConvLayer(\n            (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_1): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 128\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n              )\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n        (bl_2): NewResBlockTwist(\n          (convs): Sequential(\n            (conv_0): ConvLayer(\n              (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_1_twist): ConvLayerTwist(\n              (conv): ConvTwist(\n                twist: False, permute: False, same: True, groups: 128\n                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n              )\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act_fn): ReLU(inplace=True)\n            )\n            (conv_2): ConvLayer(\n              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (merge): ReLU(inplace=True)\n        )\n      )\n    )</pre> <pre><code>model.block = ResBlockTwist\n</code></pre> <pre><code>m = model()\n</code></pre> <pre><code>m\n</code></pre> output <pre>Sequential(\n      model Net\n      (stem): Sequential(\n        (conv_0): ConvLayer(\n          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_1): ConvLayer(\n          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (conv_2): ConvLayer(\n          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): ReLU(inplace=True)\n        )\n        (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      )\n      (body): Sequential(\n        (l_0): Sequential(\n          (bl_0): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 16\n                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n                )\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (idconv): ConvLayer(\n              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 16\n                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n                )\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_2): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 16\n                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n                )\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n        (l_1): Sequential(\n          (bl_0): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: False, groups: 32\n                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n                )\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n            (idconv): ConvLayer(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 32\n                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n                )\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_2): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 32\n                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n                )\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_3): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 32\n                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n                )\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n        (l_2): Sequential(\n          (bl_0): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: False, groups: 64\n                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n                )\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n            (idconv): ConvLayer(\n              (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 64\n                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n                )\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_2): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 64\n                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n                )\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_3): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 64\n                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n                )\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_4): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 64\n                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n                )\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_5): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 64\n                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n                )\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n        (l_3): Sequential(\n          (bl_0): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: False, groups: 128\n                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n                )\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n            (idconv): ConvLayer(\n              (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_1): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 128\n                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n                )\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n          (bl_2): ResBlockTwist(\n            (convs): Sequential(\n              (conv_0): ConvLayer(\n                (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_1_twist): ConvLayerTwist(\n                (conv): ConvTwist(\n                  twist: False, permute: False, same: True, groups: 128\n                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n                )\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (act_fn): ReLU(inplace=True)\n              )\n              (conv_2): ConvLayer(\n                (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (act_fn): ReLU(inplace=True)\n          )\n        )\n      )\n      (head): Sequential(\n        (pool): AdaptiveAvgPool2d(output_size=1)\n        (flat): Flatten()\n        (fc): Linear(in_features=2048, out_features=1000, bias=True)\n      )\n    )</pre> <pre><code>m.stem\n</code></pre> output <pre>Sequential(\n      (conv_0): ConvLayer(\n        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (conv_1): ConvLayer(\n        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (conv_2): ConvLayer(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): ReLU(inplace=True)\n      )\n      (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )</pre> <pre><code>m.head\n</code></pre> output <pre>Sequential(\n      (pool): AdaptiveAvgPool2d(output_size=1)\n      (flat): Flatten()\n      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n    )</pre> <pre><code>m.body.l_0\n</code></pre> output <pre>Sequential(\n      (bl_0): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 16\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n            )\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (idconv): ConvLayer(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_1): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 16\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n            )\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_2): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 16\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n            )\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n    )</pre> <pre><code>m.body.l_1\n</code></pre> output <pre>Sequential(\n      (bl_0): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: False, groups: 32\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n            )\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (idconv): ConvLayer(\n          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_1): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 32\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            )\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_2): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 32\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            )\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_3): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 32\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            )\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n    )</pre> <pre><code>m.body.l_2\n</code></pre> output <pre>Sequential(\n      (bl_0): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: False, groups: 64\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n            )\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (idconv): ConvLayer(\n          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_1): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 64\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n            )\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_2): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 64\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n            )\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_3): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 64\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n            )\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_4): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 64\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n            )\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_5): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 64\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n            )\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n    )</pre> <pre><code>m.body.l_3\n</code></pre> output <pre>Sequential(\n      (bl_0): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: False, groups: 128\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n            )\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (idconv): ConvLayer(\n          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_1): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 128\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n            )\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n      (bl_2): ResBlockTwist(\n        (convs): Sequential(\n          (conv_0): ConvLayer(\n            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_1_twist): ConvLayerTwist(\n            (conv): ConvTwist(\n              twist: False, permute: False, same: True, groups: 128\n              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n            )\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act_fn): ReLU(inplace=True)\n          )\n          (conv_2): ConvLayer(\n            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (act_fn): ReLU(inplace=True)\n      )\n    )</pre> <p>model_constructor by ayasyrev</p>"},{"location":"06_ConvMixer/","title":"ConvMixer","text":"<p>ConvMixer model.</p> <p>Implementation of ConvMixer. ConvMixer - ICLR 2022 submission \"Patches Are All You Need?\". Adopted from https://github.com/tmp-iclr/convmixer Home for convmixer: https://github.com/locuslab/convmixer</p> <p>Purpose of this implementation - possibilities for tune this model. For example - play with activation function, initialization etc.  </p>"},{"location":"06_ConvMixer/#import-and-create-model","title":"Import and create model","text":"<p>Base class for model - ConvMixer, return pytorch Sequential model.  </p> <pre><code>from model_constructor import ConvMixer\n</code></pre> <p>Now we can create convmixer model:</p> <pre><code>convmixer_1024_20 = ConvMixer(dim=1024, depth=20)\n</code></pre> <pre><code>convmixer_1024_20\n</code></pre> output <pre>ConvMixer(\n      (0): ConvLayer(\n        (conv): Conv2d(3, 1024, kernel_size=(7, 7), stride=(7, 7))\n        (act_fn): GELU(approximate='none')\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (19): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (20): Sequential(\n        (0): Residual(\n          (fn): ConvLayer(\n            (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n            (act_fn): GELU(approximate='none')\n            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (act_fn): GELU(approximate='none')\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (21): AdaptiveAvgPool2d(output_size=(1, 1))\n      (22): Flatten(start_dim=1, end_dim=-1)\n      (23): Linear(in_features=1024, out_features=1000, bias=True)\n    )</pre>"},{"location":"06_ConvMixer/#change-activation-function","title":"Change activation function.","text":"<p>Lets create model with Mish (import it from torch) instead of GELU.</p> <pre><code>convmixer_1024_20 = ConvMixer(dim=1024, depth=20, act_fn=Mish())\n</code></pre> <pre><code>convmixer_1024_20[0]\n</code></pre> output <pre>ConvLayer(\n      (conv): Conv2d(3, 1024, kernel_size=(7, 7), stride=(7, 7))\n      (act_fn): Mish()\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )</pre> <pre><code>convmixer_1024_20[1]\n</code></pre> output <pre>Sequential(\n      (0): Residual(\n        (fn): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n          (act_fn): Mish()\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): ConvLayer(\n        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (act_fn): Mish()\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )</pre>"},{"location":"06_ConvMixer/#pre-activation","title":"Pre activation","text":"<p>Activation function before convolution.</p> <pre><code>convmixer_1024_20 = ConvMixer(dim=1024, depth=20, act_fn=Mish(), pre_act=True)\n</code></pre> <pre><code>convmixer_1024_20[0]\n</code></pre> output <pre>ConvLayer(\n      (conv): Conv2d(3, 1024, kernel_size=(7, 7), stride=(7, 7))\n      (act_fn): Mish()\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )</pre> <pre><code>convmixer_1024_20[1]\n</code></pre> output <pre>Sequential(\n      (0): Residual(\n        (fn): ConvLayer(\n          (act_fn): Mish()\n          (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): ConvLayer(\n        (act_fn): Mish()\n        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )</pre>"},{"location":"06_ConvMixer/#batchnorm-before-activation","title":"BatchNorm before activation.","text":"<pre><code>convmixer_1024_20 = ConvMixer(dim=1024, depth=20, act_fn=Mish(), bn_1st=True)\n</code></pre> <pre><code>convmixer_1024_20[0]\n</code></pre> output <pre>ConvLayer(\n      (conv): Conv2d(3, 1024, kernel_size=(7, 7), stride=(7, 7))\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act_fn): Mish()\n    )</pre> <pre><code>convmixer_1024_20[1]\n</code></pre> output <pre>Sequential(\n      (0): Residual(\n        (fn): ConvLayer(\n          (conv): Conv2d(1024, 1024, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=1024)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act_fn): Mish()\n        )\n      )\n      (1): ConvLayer(\n        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act_fn): Mish()\n      )\n    )</pre>"}]}