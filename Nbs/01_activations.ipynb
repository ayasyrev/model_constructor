{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations functions.\n",
    "\n",
    "> Activations functions.  Set of act_fn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions, forked from https://github.com/rwightman/pytorch-image-models/timm/models/layers/activations.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mish: Self Regularized  \n",
    "Non-Monotonic Activation Function  \n",
    "https://github.com/digantamisra98/Mish  \n",
    "fastai forum discussion https://forums.fast.ai/t/meet-mish-new-activation-function-possible-successor-to-relu  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mish is in Pytorch from version 1.9. Use this version!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# forked from https://github.com/rwightman/pytorch-image-models/timm/models/layers/activations.py\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from nbdev.showdoc import show_doc\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def print_doc(func_name):\n",
    "    doc = show_doc(func_name, title_level=4, disp=False)\n",
    "    display(Markdown(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mish, MishJit, MishJitMe - memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_constructor.activations import mish, Mish, MishJit, MishMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"mish\" class=\"doc_header\"><code>mish</code><a href=\"https://github.com/ayasyrev/model_constructor/tree/master/model_constructor/activations.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>mish</code>(**`x`**, **`inplace`**:`bool`=*`False`*)\n",
       "\n",
       "Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n",
       "NOTE: I don't have a working inplace variant"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Mish\" class=\"doc_header\"><code>class</code> <code>Mish</code><a href=\"torch/nn/modules/activation.py#L401\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Mish</code>(**`inplace`**:`bool`=*`False`*) :: `Module`\n",
       "\n",
       "Applies the Mish function, element-wise.\n",
       "Mish: A Self Regularized Non-Monotonic Neural Activation Function.\n",
       "\n",
       ".. math::\n",
       "    \\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\n",
       "\n",
       ".. note::\n",
       "    See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, *)` where `*` means, any number of additional\n",
       "      dimensions\n",
       "    - Output: :math:`(N, *)`, same shape as the input\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Mish()\n",
       "    >>> input = torch.randn(2)\n",
       "    >>> output = m(input)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"MishJit\" class=\"doc_header\"><code>class</code> <code>MishJit</code><a href=\"https://github.com/ayasyrev/model_constructor/tree/master/model_constructor/activations.py#L40\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>MishJit</code>(**`inplace`**:`bool`=*`False`*) :: `Module`\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super(Model, self).__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"MishMe\" class=\"doc_header\"><code>class</code> <code>MishMe</code><a href=\"https://github.com/ayasyrev/model_constructor/tree/master/model_constructor/activations.py#L81\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>MishMe</code>(**`inplace`**:`bool`=*`False`*) :: `Module`\n",
       "\n",
       "Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n",
       "A memory efficient, jit scripted variant of Mish"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "print_doc(mish)\n",
    "print_doc(Mish)\n",
    "print_doc(MishJit)\n",
    "print_doc(MishMe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HardMishJit, HardMishJitMe - memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_constructor.activations import HardMishJit, HardMishMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HardMishJit\" class=\"doc_header\"><code>class</code> <code>HardMishJit</code><a href=\"https://github.com/ayasyrev/model_constructor/tree/master/model_constructor/activations.py#L100\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HardMishJit</code>(**`inplace`**:`bool`=*`False`*) :: `Module`\n",
       "\n",
       "Hard Mish\n",
       "Experimental, based on notes by Mish author Diganta Misra at\n",
       "  https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HardMishMe\" class=\"doc_header\"><code>class</code> <code>HardMishMe</code><a href=\"https://github.com/ayasyrev/model_constructor/tree/master/model_constructor/activations.py#L144\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HardMishMe</code>(**`inplace`**:`bool`=*`False`*) :: `Module`\n",
       "\n",
       "A memory efficient, jit scripted variant of Hard Mish\n",
       "Experimental, based on notes by Mish author Diganta Misra at\n",
       "  https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "print_doc(HardMishJit)\n",
    "print_doc(HardMishMe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end\n",
    "model_constructor\n",
    "by ayasyrev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
