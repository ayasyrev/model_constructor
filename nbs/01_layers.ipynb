{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:02:28.613591Z",
     "start_time": "2020-09-15T09:02:28.034529Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:02:28.724960Z",
     "start_time": "2020-09-15T09:02:28.712914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to model_constructor.layers,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "%nbdev_default_export layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Basic layers for constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:02:29.280009Z",
     "start_time": "2020-09-15T09:02:29.274755Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "# from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:02:29.881698Z",
     "start_time": "2020-09-15T09:02:29.560082Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.utils import spectral_norm # weight_norm, \n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:02:59.401503Z",
     "start_time": "2020-09-15T09:02:59.394107Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class Flatten(nn.Module):\n",
    "    '''flat x to vector'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x): return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:03:06.151213Z",
     "start_time": "2020-09-15T09:03:06.144829Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def noop(x): return x\n",
    "\n",
    "class Noop(nn.Module): \n",
    "    '''Dummy module'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:03:32.218769Z",
     "start_time": "2020-09-15T09:03:32.206265Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "class ConvLayer(nn.Sequential):\n",
    "    \"\"\"Basic conv layers block\"\"\"\n",
    "    Conv2d = nn.Conv2d\n",
    "    def __init__(self, ni, nf, ks=3, stride=1, \n",
    "            act=True,  act_fn=act_fn, \n",
    "            bn_layer=True, bn_1st=True, zero_bn=False, \n",
    "            padding=None, bias=False, groups=1, **kwargs):\n",
    "\n",
    "        if padding==None: padding = ks//2  \n",
    "        layers = [('conv', self.Conv2d(ni, nf, ks, stride=stride, padding=padding, bias=bias, groups=groups))]\n",
    "        act_bn = [('act_fn', act_fn)] if act else []\n",
    "        if bn_layer:\n",
    "            bn = nn.BatchNorm2d(nf)\n",
    "            nn.init.constant_(bn.weight, 0. if zero_bn else 1.) \n",
    "            act_bn += [('bn', bn)]\n",
    "        if bn_1st: act_bn.reverse()\n",
    "        layers += act_bn\n",
    "        super().__init__(OrderedDict(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:04:12.561785Z",
     "start_time": "2020-09-15T09:04:12.552909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act_fn): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = ConvLayer(32, 64)\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:04:13.100662Z",
     "start_time": "2020-09-15T09:04:13.083970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = ConvLayer(32, 64, act=False)\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:04:13.619415Z",
     "start_time": "2020-09-15T09:04:13.614435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (act_fn): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = ConvLayer(32, 64, bn_layer=False)\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:04:14.115042Z",
     "start_time": "2020-09-15T09:04:14.100292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act_fn): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = ConvLayer(32, 64, bn_1st=True)\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:04:14.808440Z",
     "start_time": "2020-09-15T09:04:14.798904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act_fn): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = ConvLayer(32, 64, bn_1st=True, act_fn=nn.LeakyReLU())\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:09:38.178529Z",
     "start_time": "2020-09-15T09:09:38.161811Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "bs = 8\n",
    "xb = torch.randn(bs, 32, 32, 32)\n",
    "y = conv_layer(xb)\n",
    "y.shape\n",
    "assert y.shape == torch.Size([bs, 64, 32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:06:35.947787Z",
     "start_time": "2020-09-15T09:06:35.932076Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# SA module from mxresnet at fastai. todo - add persons!!!\n",
    "\n",
    "#Unmodified from https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "def conv1d(ni:int, no:int, ks:int=1, stride:int=1, padding:int=0, bias:bool=False):\n",
    "    \"Create and initialize a `nn.Conv1d` layer with spectral normalization.\"\n",
    "    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n",
    "    nn.init.kaiming_normal_(conv.weight)\n",
    "    if bias: conv.bias.data.zero_()\n",
    "    return spectral_norm(conv)\n",
    "\n",
    "\n",
    "# Adapted from SelfAttention layer at https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "# Inspired by https://arxiv.org/pdf/1805.08318.pdf\n",
    "class SimpleSelfAttention(nn.Module):\n",
    "    def __init__(self, n_in:int, ks=1, sym=False):#, n_out:int):\n",
    "        super().__init__()\n",
    "        self.conv = conv1d(n_in, n_in, ks, padding=ks//2, bias=False)      \n",
    "        self.gamma = nn.Parameter(torch.tensor([0.]))\n",
    "        self.sym = sym\n",
    "        self.n_in = n_in\n",
    "    def forward(self,x):\n",
    "        if self.sym:\n",
    "            # symmetry hack by https://github.com/mgrankin\n",
    "            c = self.conv.weight.view(self.n_in,self.n_in)\n",
    "            c = (c + c.t())/2\n",
    "            self.conv.weight = c.view(self.n_in,self.n_in,1)\n",
    "        size = x.size()  \n",
    "        x = x.view(*size[:2],-1)   # (C,N)\n",
    "        # changed the order of mutiplication to avoid O(N^2) complexity\n",
    "        # (x*xT)*(W*x) instead of (x*(xT*(W*x)))\n",
    "        convx = self.conv(x)   # (C,C) * (C,N) = (C,N)   => O(NC^2)\n",
    "        xxT = torch.bmm(x,x.permute(0,2,1).contiguous())   # (C,N) * (N,C) = (C,C)   => O(NC^2)\n",
    "        o = torch.bmm(xxT, convx)   # (C,C) * (C,N) = (C,N)   => O(NC^2)\n",
    "        o = self.gamma * o + x\n",
    "        return o.view(*size).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:06:43.209459Z",
     "start_time": "2020-09-15T09:06:43.195928Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class SEBlock(nn.Module):\n",
    "    \"se block\"\n",
    "    se_layer = nn.Linear\n",
    "    act_fn = nn.ReLU(inplace=True)\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "        ch = c // r\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            OrderedDict([\n",
    "            ('fc_reduce', self.se_layer(c, ch, bias=False)),\n",
    "            ('se_act', self.act_fn),\n",
    "            ('fc_expand', self.se_layer(ch, c, bias=False)),\n",
    "            ('sigmoid', nn.Sigmoid())\n",
    "            ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, _, _ = x.shape\n",
    "        y = self.squeeze(x).view(bs, c)\n",
    "        y = self.excitation(y).view(bs, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:07:02.304137Z",
     "start_time": "2020-09-15T09:07:02.299521Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "#         return torch.mul(x, y.expand_as(x))# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:07:02.934031Z",
     "start_time": "2020-09-15T09:07:02.922985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEBlock(\n",
       "  (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "  (excitation): Sequential(\n",
       "    (fc_reduce): Linear(in_features=128, out_features=8, bias=False)\n",
       "    (se_act): ReLU(inplace=True)\n",
       "    (fc_expand): Linear(in_features=8, out_features=128, bias=False)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block = SEBlock(128)\n",
    "se_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:07:05.796153Z",
     "start_time": "2020-09-15T09:07:05.732761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bs = 8\n",
    "xb = torch.randn(bs, 128, 32, 32)\n",
    "y = se_block(xb)\n",
    "print(y.shape)\n",
    "assert y.shape == torch.Size([bs, 128, 32, 32]), f\"size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEBlockConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:07:07.917795Z",
     "start_time": "2020-09-15T09:07:07.883347Z"
    }
   },
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class SEBlockConv(nn.Module):\n",
    "    \"se block with conv on excitation\"\n",
    "    se_layer = nn.Conv2d\n",
    "    act_fn = nn.ReLU(inplace=True)\n",
    "    def __init__(self, c, r=16):\n",
    "        super().__init__()\n",
    "#         c_in = math.ceil(c//r/8)*8\n",
    "        c_in = c//r\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(OrderedDict([\n",
    "            ('conv_reduce', self.se_layer(c, c_in, 1, bias=False)),\n",
    "            ('se_act', self.act_fn),\n",
    "            ('conv_expand', self.se_layer(c_in, c, 1, bias=False)),\n",
    "            ('sigmoid', nn.Sigmoid())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.squeeze(x)\n",
    "        y = self.excitation(y)\n",
    "        return x * y.expand_as(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:07:10.529716Z",
     "start_time": "2020-09-15T09:07:10.520001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEBlockConv(\n",
       "  (squeeze): AdaptiveAvgPool2d(output_size=1)\n",
       "  (excitation): Sequential(\n",
       "    (conv_reduce): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (se_act): ReLU(inplace=True)\n",
       "    (conv_expand): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block = SEBlockConv(128)\n",
    "se_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:07:12.126044Z",
     "start_time": "2020-09-15T09:07:12.106701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bs = 8\n",
    "xb = torch.randn(bs, 128, 32, 32)\n",
    "y = se_block(xb)\n",
    "print(y.shape)\n",
    "assert y.shape == torch.Size([bs, 128, 32, 32]), f\"size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end\n",
    "model_constructor\n",
    "by ayasyrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T07:29:31.169362Z",
     "start_time": "2020-09-19T07:29:31.163089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nbdev_hide` not found.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
